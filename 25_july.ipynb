{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97c13661-a2d9-470c-ae54-9f7969d26168",
   "metadata": {},
   "source": [
    "# FACTORIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "68132e7b-f630-4c17-a583-2ae2df7c3beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93326215443944152681699238856266700490715968264381621468592963895217599993229915608941463976156518286253697920827223758251185210916864000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "#Built-in\n",
    "import math\n",
    "result = math.factorial(100)\n",
    "print(result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cae4d89b-f916-4af3-9093-52fe3fa22c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93326215443944152681699238856266700490715968264381621468592963895217599993229915608941463976156518286253697920827223758251185210916864000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "#Wihout built-in\n",
    "def factorial(n):\n",
    "    fact = 1\n",
    "    for i in range(2, n + 1):\n",
    "        fact *= i\n",
    "    return fact\n",
    "\n",
    "result = factorial(100)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a38847a-06e1-4828-b6aa-bc64bcf09231",
   "metadata": {},
   "source": [
    "# LOOP IN STRINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9413e981-188d-4cd4-b88d-2d336357821b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789\n"
     ]
    }
   ],
   "source": [
    "s=''\n",
    "for i in range(10):\n",
    "    s+=str(i)\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378ba630-57d6-4079-8048-a3bc7bf9279d",
   "metadata": {},
   "source": [
    "WHY BAD PRACTICE IN STRINGS?\n",
    "1. Strings are Immutable:\n",
    "    Every time you do s += str(i), Python creates a new string in memory.\n",
    "    It copies all the previous characters + the new one.\n",
    "    This happens in every iteration.\n",
    "\n",
    "2. Repeated Copying:\n",
    "    In 10 iterations, it copies parts 10 times.\n",
    "    In 1000 iterations, it copies parts 1000 times.\n",
    "    The more iterations, the slower it gets.\n",
    "\n",
    "3. Time Complexity:\n",
    "    This approach has O(n¬≤) time complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd81fca0-c507-47e8-8992-c51c572cd664",
   "metadata": {},
   "source": [
    "# LOOP IN LISTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b68aa505-6c86-4c59-8dfa-dccadc381da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0123456789\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parts = []                # Step 1: Create an empty list\n",
    "for i in range(10):       # Step 2: Loop through 0 to 9\n",
    "    parts.append(str(i))  # Step 3: Append each number as a string\n",
    "\n",
    "s = ''.join(parts)        # Step 4: Join all parts into a single string\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa25637-47a6-4e28-835d-bff793799c28",
   "metadata": {},
   "source": [
    "# PRINTING ADDRESS/ID  OF STRINGS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fa406d17-48e9-414c-8013-be4ad715f225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140717584979648\n",
      "140717584979648 140717584979648\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#id immutable \n",
    "s=''\n",
    "print(id(s))\n",
    "\n",
    "a1 = ''\n",
    "a2 = ''\n",
    "print(id(a1), id(a2))   # Same ID\n",
    "print(s1 is s2)         # True (same object)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e278ab-2755-46bf-8104-5ceaeb51f139",
   "metadata": {},
   "source": [
    "# ASCII CHARACTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ea32581c-b2b5-44db-9637-953dafc9de86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter start of ASCII range:  38\n",
      "Enter end of ASCII range:  127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ASCII characters from 38 to 127:\n",
      "\n",
      "38: &\n",
      "39: '\n",
      "40: (\n",
      "41: )\n",
      "42: *\n",
      "43: +\n",
      "44: ,\n",
      "45: -\n",
      "46: .\n",
      "47: /\n",
      "48: 0\n",
      "49: 1\n",
      "50: 2\n",
      "51: 3\n",
      "52: 4\n",
      "53: 5\n",
      "54: 6\n",
      "55: 7\n",
      "56: 8\n",
      "57: 9\n",
      "58: :\n",
      "59: ;\n",
      "60: <\n",
      "61: =\n",
      "62: >\n",
      "63: ?\n",
      "64: @\n",
      "65: A\n",
      "66: B\n",
      "67: C\n",
      "68: D\n",
      "69: E\n",
      "70: F\n",
      "71: G\n",
      "72: H\n",
      "73: I\n",
      "74: J\n",
      "75: K\n",
      "76: L\n",
      "77: M\n",
      "78: N\n",
      "79: O\n",
      "80: P\n",
      "81: Q\n",
      "82: R\n",
      "83: S\n",
      "84: T\n",
      "85: U\n",
      "86: V\n",
      "87: W\n",
      "88: X\n",
      "89: Y\n",
      "90: Z\n",
      "91: [\n",
      "92: \\\n",
      "93: ]\n",
      "94: ^\n",
      "95: _\n",
      "96: `\n",
      "97: a\n",
      "98: b\n",
      "99: c\n",
      "100: d\n",
      "101: e\n",
      "102: f\n",
      "103: g\n",
      "104: h\n",
      "105: i\n",
      "106: j\n",
      "107: k\n",
      "108: l\n",
      "109: m\n",
      "110: n\n",
      "111: o\n",
      "112: p\n",
      "113: q\n",
      "114: r\n",
      "115: s\n",
      "116: t\n",
      "117: u\n",
      "118: v\n",
      "119: w\n",
      "120: x\n",
      "121: y\n",
      "122: z\n",
      "123: {\n",
      "124: |\n",
      "125: }\n",
      "126: ~\n",
      "127: \n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = int(input(\"Enter start of ASCII range: \"))\n",
    "end = int(input(\"Enter end of ASCII range: \"))\n",
    "\n",
    "print(f\"\\nASCII characters from {start} to {end}:\\n\")\n",
    "\n",
    "for i in range(start, end + 1):\n",
    "    ch = chr(i)\n",
    "    print(f\"{i}: {ch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dddf6a8-324a-4a73-bff2-b09b510a5dc4",
   "metadata": {},
   "source": [
    "# ENCODING EQUIVALENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4db95450-a832-4824-9ee9-8e12f4d17f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Char  | ASCII  | UTF-8 Encoding \n",
      "-----------------------------------\n",
      " ' '   |   32   |      b' '      \n",
      " '!'   |   33   |      b'!'      \n",
      " '\"'   |   34   |      b'\"'      \n",
      " '#'   |   35   |      b'#'      \n",
      " '$'   |   36   |      b'$'      \n",
      " '%'   |   37   |      b'%'      \n",
      " '&'   |   38   |      b'&'      \n",
      " \"'\"   |   39   |      b\"'\"      \n",
      " '('   |   40   |      b'('      \n",
      " ')'   |   41   |      b')'      \n",
      " '*'   |   42   |      b'*'      \n",
      " '+'   |   43   |      b'+'      \n",
      " ','   |   44   |      b','      \n",
      " '-'   |   45   |      b'-'      \n",
      " '.'   |   46   |      b'.'      \n",
      " '/'   |   47   |      b'/'      \n",
      " '0'   |   48   |      b'0'      \n",
      " '1'   |   49   |      b'1'      \n",
      " '2'   |   50   |      b'2'      \n",
      " '3'   |   51   |      b'3'      \n",
      " '4'   |   52   |      b'4'      \n",
      " '5'   |   53   |      b'5'      \n",
      " '6'   |   54   |      b'6'      \n",
      " '7'   |   55   |      b'7'      \n",
      " '8'   |   56   |      b'8'      \n",
      " '9'   |   57   |      b'9'      \n",
      " ':'   |   58   |      b':'      \n",
      " ';'   |   59   |      b';'      \n",
      " '<'   |   60   |      b'<'      \n",
      " '='   |   61   |      b'='      \n",
      " '>'   |   62   |      b'>'      \n",
      " '?'   |   63   |      b'?'      \n",
      " '@'   |   64   |      b'@'      \n",
      " 'A'   |   65   |      b'A'      \n",
      " 'B'   |   66   |      b'B'      \n",
      " 'C'   |   67   |      b'C'      \n",
      " 'D'   |   68   |      b'D'      \n",
      " 'E'   |   69   |      b'E'      \n",
      " 'F'   |   70   |      b'F'      \n",
      " 'G'   |   71   |      b'G'      \n",
      " 'H'   |   72   |      b'H'      \n",
      " 'I'   |   73   |      b'I'      \n",
      " 'J'   |   74   |      b'J'      \n",
      " 'K'   |   75   |      b'K'      \n",
      " 'L'   |   76   |      b'L'      \n",
      " 'M'   |   77   |      b'M'      \n",
      " 'N'   |   78   |      b'N'      \n",
      " 'O'   |   79   |      b'O'      \n",
      " 'P'   |   80   |      b'P'      \n",
      " 'Q'   |   81   |      b'Q'      \n",
      " 'R'   |   82   |      b'R'      \n",
      " 'S'   |   83   |      b'S'      \n",
      " 'T'   |   84   |      b'T'      \n",
      " 'U'   |   85   |      b'U'      \n",
      " 'V'   |   86   |      b'V'      \n",
      " 'W'   |   87   |      b'W'      \n",
      " 'X'   |   88   |      b'X'      \n",
      " 'Y'   |   89   |      b'Y'      \n",
      " 'Z'   |   90   |      b'Z'      \n",
      " '['   |   91   |      b'['      \n",
      " '\\\\'  |   92   |      b'\\\\'     \n",
      " ']'   |   93   |      b']'      \n",
      " '^'   |   94   |      b'^'      \n",
      " '_'   |   95   |      b'_'      \n",
      " '`'   |   96   |      b'`'      \n",
      " 'a'   |   97   |      b'a'      \n",
      " 'b'   |   98   |      b'b'      \n",
      " 'c'   |   99   |      b'c'      \n",
      " 'd'   |  100   |      b'd'      \n",
      " 'e'   |  101   |      b'e'      \n",
      " 'f'   |  102   |      b'f'      \n",
      " 'g'   |  103   |      b'g'      \n",
      " 'h'   |  104   |      b'h'      \n",
      " 'i'   |  105   |      b'i'      \n",
      " 'j'   |  106   |      b'j'      \n",
      " 'k'   |  107   |      b'k'      \n",
      " 'l'   |  108   |      b'l'      \n",
      " 'm'   |  109   |      b'm'      \n",
      " 'n'   |  110   |      b'n'      \n",
      " 'o'   |  111   |      b'o'      \n",
      " 'p'   |  112   |      b'p'      \n",
      " 'q'   |  113   |      b'q'      \n",
      " 'r'   |  114   |      b'r'      \n",
      " 's'   |  115   |      b's'      \n",
      " 't'   |  116   |      b't'      \n",
      " 'u'   |  117   |      b'u'      \n",
      " 'v'   |  118   |      b'v'      \n",
      " 'w'   |  119   |      b'w'      \n",
      " 'x'   |  120   |      b'x'      \n",
      " 'y'   |  121   |      b'y'      \n",
      " 'z'   |  122   |      b'z'      \n",
      " '{'   |  123   |      b'{'      \n",
      " '|'   |  124   |      b'|'      \n",
      " '}'   |  125   |      b'}'      \n",
      " '~'   |  126   |      b'~'      \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"{'Char':^6} | {'ASCII':^6} | {'UTF-8 Encoding':^15}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for i in range(32, 127):  # Printable ASCII range\n",
    "    char = chr(i)\n",
    "    ascii_val = ord(char)\n",
    "    utf8_encoded = char.encode('utf-8')\n",
    "    print(f\"{char!r:^6} | {ascii_val:^6} | {str(utf8_encoded):^15}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e1829-55b2-4e71-b456-555f1f7767eb",
   "metadata": {},
   "source": [
    "# TOKENIZING AND PIPELINE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728eebd0-96e6-4d82-b9c0-5a44cd97c4ca",
   "metadata": {},
   "source": [
    "\n",
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "a8957e44-213b-4a2a-a996-ea6bc0031842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 tokens: ['The', 'Signora', 'had', 'no', 'business', 'to', 'do', 'it']\n",
      "Sentence 2 tokens: ['She', 'promised', 'us', 'rooms', 'with', 'a', 'view']\n",
      "Sentence 3 tokens: ['Oh', ',', 'Lucy']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Sample text\n",
    "text = \"\"\"The Signora had no business to do it. She promised us rooms with a view. Oh, Lucy!\"\"\"\n",
    "\n",
    "# Split manually by sentence-ending punctuation (basic way to avoid punkt)\n",
    "import re\n",
    "sentences = re.split(r'[.!?]\\s*', text.strip())\n",
    "sentences = [s for s in sentences if s]  # Remove any empty strings\n",
    "\n",
    "# Tokenize words using NLTK's simple word tokenizer (no punkt)\n",
    "words = []\n",
    "for sentence in sentences:\n",
    "    # Use RegexpTokenizer from NLTK (does not rely on punkt)\n",
    "    tokenizer = nltk.RegexpTokenizer(r'\\w+|\\$[\\d\\.]+|\\S+')\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    words.append(tokens)\n",
    "\n",
    "# Print results\n",
    "for i, token_list in enumerate(words):\n",
    "    print(f\"Sentence {i+1} tokens: {token_list}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a397ca01-e578-49a2-bc2e-13f74ba32d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1 tokens: ['The', 'Signora', 'had', 'no', 'business', 'to', 'do', 'it']\n",
      "Sentence 2 tokens: ['She', 'promised', 'us', 'rooms', 'with', 'a', 'view']\n",
      "Sentence 3 tokens: ['Oh', ',', 'Lucy']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Step 1: Define Pipeline Components\n",
    "def sentence_split(text):\n",
    "    # Split text using sentence-ending punctuation\n",
    "    return [s for s in re.split(r'[.!?]\\s*', text.strip()) if s]\n",
    "\n",
    "def word_tokenize_pipeline(sentences):\n",
    "    # Tokenizer that doesn't use punkt\n",
    "    tokenizer = RegexpTokenizer(r'\\w+|\\$[\\d\\.]+|\\S+')\n",
    "    return [tokenizer.tokenize(sentence) for sentence in sentences]\n",
    "\n",
    "# Step 2: Input Text\n",
    "text = \"\"\"The Signora had no business to do it. She promised us rooms with a view. Oh, Lucy!\"\"\"\n",
    "\n",
    "# Step 3: Run the NLP Pipeline\n",
    "sentences = sentence_split(text)\n",
    "tokenized_sentences = word_tokenize_pipeline(sentences)\n",
    "\n",
    "# Step 4: Output the Results\n",
    "for i, tokens in enumerate(tokenized_sentences):\n",
    "    print(f\"Sentence {i+1} tokens: {tokens}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c6664c-392e-4d6c-82aa-f0d1289a049b",
   "metadata": {},
   "source": [
    "# UNICODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a73cfc45-0a2d-45ec-8a8c-f9f2f4dfa31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì\n",
      "‚úè\n",
      "üòÄ\n"
     ]
    }
   ],
   "source": [
    "print(chr(10003))  \n",
    "print(chr(9999))   \n",
    "print(chr(128512)) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
